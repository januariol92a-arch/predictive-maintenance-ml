{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982629cc",
   "metadata": {},
   "source": [
    "\n",
    "# Mantenimiento Predictivo con Machine Learning\n",
    "**Autor:** Januario Tapiero Tique  \n",
    "**Objetivo:** Proyecto profesional y didáctico para predecir fallas de equipos (clasificación) y vida útil restante (regresión), con *clustering + PCA* para análisis exploratorio.\n",
    "\n",
    "> Este notebook es pedagógico y a la vez profesional. Evita *data leakage* usando `Pipeline`, incluye métricas correctas, validación cruzada y visualizaciones claras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instalaciones mínimas (ejecutar si hace falta)\n",
    "# !pip install -U pip numpy pandas scikit-learn matplotlib joblib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
    "                             accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             mean_squared_error, r2_score)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from joblib import dump, load\n",
    "\n",
    "import os, sys\n",
    "sys.path.append('../src')\n",
    "from utils import make_synthetic_maint_data\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c617ac64",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Generar / Cargar datos\n",
    "Usaremos un **dataset sintético reproducible** que simula sensores, condiciones de operación y la **RUL** (vida útil restante).  \n",
    "También creamos una etiqueta de **clasificación** `fail_in_H` (fallará en los próximos 10 ciclos).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = make_synthetic_maint_data(n_units=220, cycles=130, random_state=RANDOM_STATE)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0bd1d",
   "metadata": {},
   "source": [
    "\n",
    "## 2. EDA rápido (exploración)\n",
    "Revisamos distribución del target, correlaciones aproximadas, y ejemplos temporales por unidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca252d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribución de la etiqueta de clasificación\n",
    "class_counts = df['fail_in_H'].value_counts().sort_index()\n",
    "print(class_counts)\n",
    "\n",
    "fig = plt.figure()\n",
    "class_counts.plot(kind='bar')\n",
    "plt.title('Distribución de la etiqueta: fail_in_H')\n",
    "plt.xlabel('Clase')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "# Correlación con RUL (regresión)\n",
    "corr = df[['s1','s2','s3','vibration','temp','pressure','load','RUL']].corr()['RUL'].sort_values(ascending=False)\n",
    "print('Correlación con RUL:\\n', corr)\n",
    "\n",
    "# Ejemplo de serie temporal de una unidad\n",
    "sample_unit = df[df['unit']==0]\n",
    "fig = plt.figure()\n",
    "plt.plot(sample_unit['time'], sample_unit['vibration'])\n",
    "plt.title('Vibración vs tiempo (unidad 0)')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Vibración')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cf6088",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Split train/test sin fuga de datos\n",
    "Dividimos por **muestras** (no por tiempo) para simplificar este ejemplo sintético.\n",
    "En casos reales por serie temporal, conviene usar **split por tiempo**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb37352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_cols = ['load','ambient','s1','s2','s3','vibration','temp','pressure']\n",
    "\n",
    "# Clasificación\n",
    "X_cls = df[feature_cols].values\n",
    "y_cls = df['fail_in_H'].values\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_cls, y_cls, test_size=0.2, random_state=RANDOM_STATE, stratify=y_cls\n",
    ")\n",
    "\n",
    "# Regresión\n",
    "X_reg = df[feature_cols].values\n",
    "y_reg = df['RUL'].values\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "Xc_train.shape, Xr_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f34550",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Clasificación (¿fallará pronto?)\n",
    "Entrenamos dos modelos: **LogisticRegression** (lineal, interpretable) y **RandomForestClassifier** (no lineal, robusto).  \n",
    "Usamos `Pipeline` con `StandardScaler` donde aplica y validación cruzada estratificada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Modelo 1: Regresión Logística\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=200, class_weight='balanced', random_state=RANDOM_STATE))])\n",
    "scores_lr = cross_val_score(pipe_lr, Xc_train, yc_train, cv=skf, scoring='f1')\n",
    "print('LogReg CV F1:', scores_lr.mean().round(3), '+/-', scores_lr.std().round(3))\n",
    "pipe_lr.fit(Xc_train, yc_train)\n",
    "yc_pred_lr = pipe_lr.predict(Xc_test)\n",
    "yc_prob_lr = pipe_lr.predict_proba(Xc_test)[:,1]\n",
    "\n",
    "# Métricas\n",
    "print('=== Logistic Regression Test ===')\n",
    "print('Accuracy:', accuracy_score(yc_test, yc_pred_lr).round(3))\n",
    "print('F1:', f1_score(yc_test, yc_pred_lr).round(3))\n",
    "print('Precision:', precision_score(yc_test, yc_pred_lr).round(3))\n",
    "print('Recall:', recall_score(yc_test, yc_pred_lr).round(3))\n",
    "print('\\nMatriz de confusión:\\n', confusion_matrix(yc_test, yc_pred_lr))\n",
    "print('\\nReporte:\\n', classification_report(yc_test, yc_pred_lr))\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, _ = roc_curve(yc_test, yc_prob_lr)\n",
    "auc_lr = roc_auc_score(yc_test, yc_prob_lr)\n",
    "fig = plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC = {auc_lr:.3f}')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.title('Curva ROC - Logistic Regression')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Modelo 2: RandomForestClassifier (tuning pequeño)\n",
    "pipe_rf = Pipeline([('clf', RandomForestClassifier(random_state=RANDOM_STATE))])\n",
    "param_grid = {'clf__n_estimators':[150,250], 'clf__max_depth':[None,12]}\n",
    "gs = GridSearchCV(pipe_rf, param_grid, cv=skf, scoring='f1', n_jobs=-1)\n",
    "gs.fit(Xc_train, yc_train)\n",
    "best_rf = gs.best_estimator_\n",
    "print('Mejor RF:', gs.best_params_, 'CV F1:', gs.best_score_.round(3))\n",
    "\n",
    "yc_pred_rf = best_rf.predict(Xc_test)\n",
    "yc_prob_rf = best_rf.predict_proba(Xc_test)[:,1]\n",
    "print('=== Random Forest Test ===')\n",
    "print('Accuracy:', accuracy_score(yc_test, yc_pred_rf).round(3))\n",
    "print('F1:', f1_score(yc_test, yc_pred_rf).round(3))\n",
    "print('\\nMatriz de confusión:\\n', confusion_matrix(yc_test, yc_pred_rf))\n",
    "\n",
    "# Guardar mejor modelo\n",
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "from joblib import dump\n",
    "dump(best_rf, '../models/classifier_random_forest.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ad365",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Regresión (RUL)\n",
    "Comparamos **Ridge**, **Lasso** y **RandomForestRegressor** usando RMSE y R².  \n",
    "Usamos `Pipeline` con escalado para modelos lineales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_reg(y_true, y_pred, name='Model'):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f'{name} -> RMSE: {rmse:.2f} | R2: {r2:.3f}')\n",
    "    return rmse, r2\n",
    "\n",
    "# Ridge\n",
    "pipe_ridge = Pipeline([('scaler', StandardScaler()), ('reg', Ridge())])\n",
    "param_ridge = {'reg__alpha':[0.1,1.0,5.0,10.0]}\n",
    "gs_ridge = GridSearchCV(pipe_ridge, param_ridge, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_ridge.fit(Xr_train, yr_train)\n",
    "yr_pred_ridge = gs_ridge.predict(Xr_test)\n",
    "eval_reg(yr_test, yr_pred_ridge, 'Ridge')\n",
    "\n",
    "# Lasso\n",
    "pipe_lasso = Pipeline([('scaler', StandardScaler()), ('reg', Lasso(max_iter=5000))])\n",
    "param_lasso = {'reg__alpha':[0.001,0.01,0.1,1.0]}\n",
    "gs_lasso = GridSearchCV(pipe_lasso, param_lasso, cv=5, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "gs_lasso.fit(Xr_train, yr_train)\n",
    "yr_pred_lasso = gs_lasso.predict(Xr_test)\n",
    "eval_reg(yr_test, yr_pred_lasso, 'Lasso')\n",
    "\n",
    "# RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=300, random_state=RANDOM_STATE)\n",
    "rf_reg.fit(Xr_train, yr_train)\n",
    "yr_pred_rfr = rf_reg.predict(Xr_test)\n",
    "eval_reg(yr_test, yr_pred_rfr, 'RandomForestRegressor')\n",
    "\n",
    "# Importancias (RF)\n",
    "importances = rf_reg.feature_importances_\n",
    "fig = plt.figure()\n",
    "plt.bar(range(len(importances)), importances)\n",
    "plt.xticks(range(len(importances)), feature_cols, rotation=45, ha='right')\n",
    "plt.title('Importancia de características (Regresión - RF)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "from joblib import dump\n",
    "dump(rf_reg, '../models/regressor_random_forest.joblib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7ae88e",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Clustering + PCA (patrones operativos y anomalías)\n",
    "Usamos **PCA** para reducción de dimensionalidad y **K-Means** / **DBSCAN** para agrupamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "X_for_cluster = df[feature_cols].sample(n=5000, random_state=RANDOM_STATE).values\n",
    "\n",
    "# PCA a 2D\n",
    "pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X_for_cluster)\n",
    "print('Varianza explicada (2D):', pca.explained_variance_ratio_.sum().round(3))\n",
    "\n",
    "# K-Means\n",
    "kmeans = KMeans(n_clusters=3, n_init=10, random_state=RANDOM_STATE)\n",
    "km_labels = kmeans.fit_predict(X_pca)\n",
    "sil_km = silhouette_score(X_pca, km_labels)\n",
    "print('Silhouette KMeans:', round(sil_km,3))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=km_labels, s=8)\n",
    "plt.title('PCA 2D + KMeans (k=3)')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()\n",
    "\n",
    "# DBSCAN (detección de densidad y ruido)\n",
    "db = DBSCAN(eps=0.6, min_samples=10)\n",
    "db_labels = db.fit_predict(X_pca)\n",
    "valid = db_labels!=-1\n",
    "sil_db = silhouette_score(X_pca[valid], db_labels[valid]) if valid.sum()>1 and len(set(db_labels))>1 else None\n",
    "print('Silhouette DBSCAN:', sil_db)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=db_labels, s=8)\n",
    "plt.title('PCA 2D + DBSCAN')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ad938",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Exportar resultados y resumen ejecutivo\n",
    "Guardamos modelos y un **resumen ejecutivo** para stakeholders no técnicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = []\n",
    "summary.append('Proyecto: Mantenimiento Predictivo con ML')\n",
    "summary.append('Objetivo: Clasificación de fallo inminente y Regresión de RUL')\n",
    "summary.append('Modelos: LogisticRegression, RandomForest (clasificación); Ridge/Lasso/RF (regresión)')\n",
    "summary.append('Métricas clave: F1 y ROC-AUC (clasificación); RMSE y R2 (regresión)')\n",
    "summary.append('Buenas prácticas: Pipeline, escalado, CV estratificada, tuning con GridSearch, prevención de data leakage')\n",
    "summary_txt = \"\\n\".join(summary)\n",
    "\n",
    "import os\n",
    "os.makedirs('../reports', exist_ok=True)\n",
    "with open('../reports/resumen_ejecutivo.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(summary_txt)\n",
    "\n",
    "print(summary_txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42184ef9",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Conclusiones y siguientes pasos\n",
    "- En datos reales con series temporales, usar **TimeSeriesSplit** o split por tiempo.\n",
    "- Añadir **curvas PR** si hay desbalance fuerte.\n",
    "- Probar **umbrales de decisión** optimizados por métrica de negocio (ej: maximizar recall).  \n",
    "- Integrar un **dashboard** (Streamlit/Gradio) para stakeholders.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
